{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"/Users/sunilravilla/Documents/Work/7641/Project/Project_midterm/Hotel_Reviews.csv\")\n",
    "df.head()\n",
    "required_columns=['Hotel_Address','Average_Score','Hotel_Name','Negative_Review','Positive_Review','Total_Number_of_Reviews','Reviewer_Score','lat','lng']\n",
    "#filter the dataset to include only the required columns\n",
    "df2=df[required_columns]\n",
    "df2.head()\n",
    "#replace No Negative with empty string in Negative_Review column\n",
    "df2['Negative_Review']=df2['Negative_Review'].replace('No Negative', '')\n",
    "df2['Positive_Review']=df2['Positive_Review'].replace('No Positive', '')\n",
    "df2.head()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install pyabsa\n",
    "!pip install pyabsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyabsa import ATEPCCheckpointManager\n",
    "\n",
    "aspect_extractor = ATEPCCheckpointManager.get_aspect_extractor(checkpoint='english',\n",
    "                                                               auto_device=True  # False means load model on CPU\n",
    "                                                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the aspect based sentiment score\n",
    "def aspect_sentiment(s):\n",
    "    #s = 'Staff was very rude but food was delicious.The food was bad, but the service was good'\n",
    "    atepc_results = []\n",
    "    examples = [s]\n",
    "    inference_source = examples\n",
    "    atepc_result = aspect_extractor.extract_aspect(inference_source=inference_source,  #\n",
    "                                                   pred_sentiment=True, )  # Predict the sentiment of extracted aspect terms\n",
    "\n",
    "    #replace the sentiment with positive as 1 and negative as -1 and neutral as 0 in the sentiment dictionary\n",
    "\n",
    "    atepc_result[0]['sentiment'] = [1 if i == 'Positive' else -1 if i=='Negative' else 0 for i in atepc_result[0]['sentiment']]\n",
    "    \n",
    "    temp_dict = {a.lower(): b*c for a, b,\n",
    "                 c in zip(atepc_result[0]['aspect'], atepc_result[0]['sentiment'], atepc_result[0]['confidence'])}\n",
    "    return temp_dict\n",
    "\n",
    "\n",
    "#test the function\n",
    "# s = 'Staff was very rude but food was delicious.The food was bad, but the service was good'\n",
    "# aspect_sentiment(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()\n",
    "#Filter all rows with Hotel_name as Hotel Arena\n",
    "#random sample of 1000 rows\n",
    "df20=df2\n",
    "list_of_hotels=df20['Hotel_Name'].unique()\n",
    "from collections import defaultdict\n",
    "master_dict = defaultdict(dict)\n",
    "\n",
    "for i in range(650,len(list_of_hotels)):\n",
    "    # Track the progress\n",
    "    print(\"Hotel number in the list: \", i)\n",
    "    dict_hotel = defaultdict(float)\n",
    "    df_temp=df20[df20['Hotel_Name']==list_of_hotels[i]]\n",
    "  \n",
    "    \n",
    "    for j in range(df_temp.shape[0]):\n",
    "        #track the progress within the hotel\n",
    "        print(\"Review number: \", j, \"out of \", df_temp.shape[0])\n",
    "        temp_dict_1 = aspect_sentiment(df_temp.iloc[j]['Positive_Review'])\n",
    "        temp_dict_2 = aspect_sentiment(df_temp.iloc[j]['Negative_Review'])\n",
    "        for key, value in temp_dict_1.items():\n",
    "            dict_hotel[key] += value\n",
    "        for key, value in temp_dict_2.items():\n",
    "            dict_hotel[key] += value\n",
    "    master_dict[list_of_hotels[i]] = dict(dict_hotel)\n",
    "    #write the dictionary to a pickle file with the hotel name as the key and for hotel name as file name\n",
    "    import pickle\n",
    "    with open(list_of_hotels[i]+'.pkl', 'wb') as f:\n",
    "        pickle.dump(dict_hotel, f)\n",
    "    print(list_of_hotels[i])\n",
    "    \n",
    "\n",
    "dict(master_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the master dictionary to a pickle file\n",
    "import pickle\n",
    "with open('master_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(master_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#read the pickle file\n",
    "with open('master_dict.pickle', 'rb') as handle:\n",
    "    master_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check file type is .pkl and not .pickle if pickle file  then load the pickle file and form nested dictionary\n",
    "import os\n",
    "import pickle\n",
    "master_dict={}\n",
    "i=0\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".pkl\"):\n",
    "        #track the progress\n",
    "        print (i)\n",
    "        i+=1\n",
    "        with open(file, 'rb') as f:\n",
    "            master_dict[file.split('.')[0]] = pickle.load(f)\n",
    "dict(master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the master dictionary to a pickle file\n",
    "import pickle\n",
    "with open('master_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(master_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all the keys from the nested dictionary into a list\n",
    "keys=[]\n",
    "for key, value in master_dict.items():\n",
    "    for k, v in value.items():\n",
    "        keys.append(k)\n",
    "keys=list(set(keys))\n",
    "print(len(keys))\n",
    "\n",
    "#write the keys to a pickle file\n",
    "import pickle\n",
    "with open('Aspects.pickle', 'wb') as handle:\n",
    "    pickle.dump(keys, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#read the pickle file into a list\n",
    "with open('Aspects.pickle', 'rb') as handle:\n",
    "    Aspects = pickle.load(handle)\n",
    "\n",
    "print(keys[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d=master_dict\n",
    "df21 = pd.DataFrame.from_dict({(i, j) : {'confidence':d[i][j] for i in d.keys() for j in d[i].keys()} for i in d.keys() for j in d[i].keys()}, orient = 'index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df21.head()\n",
    "df21.to_csv('Hotel_name_aspect_and_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the top 10 aspects for each hotel\n",
    "df22=df21.groupby(level=0).apply(lambda x: x.sort_values('confidence', ascending=False).head(10))\n",
    "df22.head(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign index names to the dataframe\n",
    "df22.index.names = ['Hotel_Name', 'Aspect']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the top 10 aspects to a csv file\n",
    "df22.to_csv('Hotel_name_top_10_aspects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import cos, asin, sqrt, pi\n",
    "\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a)) #2*R*asin...\n",
    "\n",
    "    #test the function\n",
    "distance(52.2296756, 21.0122287, 52.406374, 21.9251681)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate two aspect values with random values\n",
    "#intialise empty dataframe\n",
    "df23 = pd.DataFrame(\n",
    "    columns=['Hotel_Name', 'Aspect_1', 'Aspect_2', 'Aspect_3', 'Aspect_4', 'Aspect_5' ,'lat', 'lng', ])\n",
    "df23['Aspect_1'] = np.random.randint(1, 40, df2.shape[0])\n",
    "df23['Aspect_2'] = np.random.randint(1, 50, df2.shape[0])\n",
    "df23['Aspect_3'] = np.random.randint(1, 35, df2.shape[0])\n",
    "df23['Aspect_4'] = np.random.randint(1, 45, df2.shape[0])\n",
    "df23['Aspect_5'] = np.random.randint(1, 70, df2.shape[0])\n",
    "df23['Hotel_Name'] = df2['Hotel_Name']\n",
    "df23['lat'] = df2['lat']\n",
    "df23['lng'] = df2['lng']\n",
    "df23.head()\n",
    "\n",
    "#grouby hotel name and calculate the mean of the aspect values ,lat and lng , reset the index and assign to a new dataframe\n",
    "df24=df23.groupby('Hotel_Name').mean().reset_index()\n",
    "df24.head()\n",
    "\n",
    "#write the dataframe to a csv file\n",
    "df24.to_csv('Hotel_name_sample_data_for_GUI.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df24.head(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c78b8c11488983031765fc26fae50f1603d4de4138f229663396b39af78eff5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
